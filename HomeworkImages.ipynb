{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of data generator objects\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "if apply_data_augmentation:\n",
    "    train_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                       width_shift_range=10,\n",
    "                                       height_shift_range=10,\n",
    "                                       zoom_range=0.3,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True,\n",
    "                                       fill_mode='constant',#when we flip, rotate, we introduce new pixels and we must set a way on how to fill\n",
    "                                       cval=0,\n",
    "                                       rescale=1/255.)\n",
    "\n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "    \n",
    "valid_data_gen = ImageDataGenerator(rescale=1/255.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting paths for training, validation and test set\n",
    "\n",
    "cwd = os.path.join(os.path.dirname(os.getcwd()),\"artificial-neural-networks-and-deep-learning-2020/MaskDataset/\")\n",
    "\n",
    "dataset_dir = os.path.join(cwd, \"training/\")\n",
    "validation_dir = os.path.join(cwd, \"validation/\")\n",
    "test_dir = os.path.join(cwd, \"test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = os.getcwd()\n",
    "print (\"The current working directory is %s\" % test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(os.path.join(cwd,'train_gt.json')) as f:\n",
    "  myJson = json.load(f)\n",
    "print(myJson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#division of images in different set\n",
    "\n",
    "for key in myJson:\n",
    "    os.rename(os.path.join(dataset_dir,key), dataset_dir+'/'+str(myJson[key])+'/'+key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset validation set to empty set\n",
    "for i in range(3):\n",
    "    curr_dir = os.path.join(cwd, \"validation/\" + str(i))\n",
    "    image_filenames = next(os.walk(curr_dir))[2]\n",
    "\n",
    "    for image_name in image_filenames:\n",
    "        os.rename(os.path.join(curr_dir,image_name), dataset_dir+'/'+str(myJson[image_name])+'/'+image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose 5% random images from the training set and move them to validation set\n",
    "random.seed(SEED)\n",
    "\n",
    "for i in range(3):\n",
    "    curr_dir = os.path.join(cwd, \"training/\" + str(i))\n",
    "    image_filenames = next(os.walk(curr_dir))[2]\n",
    "\n",
    "    for image_name in image_filenames:\n",
    "        if 100*random.random() < 5:\n",
    "            os.rename(os.path.join(curr_dir,image_name), validation_dir+'/'+str(myJson[image_name])+'/'+image_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5348 images belonging to 3 classes.\n",
      "Found 266 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#Generators for reading images dirrectly from directories\n",
    "\n",
    "img_h = 408\n",
    "img_w = 612\n",
    "\n",
    "bs=16\n",
    "\n",
    "#training generator\n",
    "train_gen = train_data_gen.flow_from_directory(dataset_dir,\n",
    "                                               target_size=(img_h,img_w),\n",
    "                                              color_mode='rgb',\n",
    "                                              batch_size=bs,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True,\n",
    "                                              seed=SEED)\n",
    "#validation generator\n",
    "valid_gen = valid_data_gen.flow_from_directory(validation_dir,\n",
    "                                               target_size=(img_h,img_w),\n",
    "                                               color_mode='rgb',\n",
    "                                              batch_size=bs,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True,\n",
    "                                              seed=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of dataset objects\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                              output_types=(tf.float32,tf.float32),\n",
    "                                              output_shapes=([None,img_h,img_w,3],[None,num_classes]))\n",
    "\n",
    "train_dataset=train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n",
    "                                              output_types=(tf.float32,tf.float32),\n",
    "                                              output_shapes=([None,img_h,img_w,3],[None,num_classes]))\n",
    "\n",
    "valid_dataset=valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterator = iter(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmented_img, target = next(iterator)\n",
    "augmented_img = np.array(augmented_img[0])\n",
    "augmented_img = augmented_img * 255\n",
    "\n",
    "plt.imshow(np.uint8(augmented_img))\n",
    "plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_f = 9\n",
    "depth = 6\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "for i in range(depth):\n",
    "    if i == 0:\n",
    "        input_shape = [img_h,img_w,3]\n",
    "    else:\n",
    "        input_shape = [None]\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(filters=start_f,\n",
    "                                    kernel_size=(3,3),\n",
    "                                    strides=(1,1),\n",
    "                                    padding='same',\n",
    "                                    input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "    start_f *=2\n",
    "    \n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "#Learning rate\n",
    "lr = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "#Validation metric used during training\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss , metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callbacks list\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'classification_experiments_')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d')\n",
    "\n",
    "exp_name='FC'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, exp_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "#Checkpoint callback\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir,'cp.ckpt'),save_weights_only=True)\n",
    "\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "#tensorboard callback\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "tb_callback=tf.keras.callbacks.TensorBoard(log_dir=tb_dir,histogram_freq=1)\n",
    "\n",
    "\n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=1)  # if 1 shows weights histograms\n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks.append(es_callback)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model.load_weights(filepath=os.path.join(cwd,'cp.ckpt'))\n",
    "\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "         epochs=100,\n",
    "         steps_per_epoch=len(train_gen),\n",
    "        validation_data=valid_dataset,\n",
    "         validation_steps=len(valid_gen),\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for creating the result in a csv file\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./results'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction computation done one image at time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "image_filenames = next(os.walk(test_dir))[2]\n",
    "\n",
    "results = {}\n",
    "for image_name in image_filenames:\n",
    "    \n",
    "    image = tf.keras.preprocessing.image.load_img(test_dir+image_name,target_size=(img_h,img_w))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "    \n",
    "    predictions = model.predict_classes(input_arr*(1/255))\n",
    "    #img = Image.open(test_dir+'/'+image_name).convert('RGB')\n",
    "    #img_array = np.array(img)\n",
    "    #img_array = np.expand_dims(img_array, 0) \n",
    "    #data_normalization\n",
    "    #print(np.argmax(predictions, axis=1)[0] )\n",
    "\n",
    "    #prediction = argmax(softmax)   # predicted class\n",
    "    \n",
    "\n",
    "    #results[image_name] = np.argmax(predictions, axis=1) [0]\n",
    "    \n",
    "    results[image_name] = predictions[0]\n",
    "\n",
    "create_csv(results)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath=os.path.join(cwd,'cp.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.preprocessing.image.load_img(test_dir+image_name,target_size=(img_h,img_w))\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])*1/255\n",
    "print(input_arr.shape)\n",
    "\n",
    "#augmented_img = augmented_img * 255\n",
    "print (input_arr)\n",
    "\n",
    "plt.imshow(np.uint8(input_arr*255)[0])\n",
    "plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
